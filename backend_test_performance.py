import requests
import sys
import json
from datetime import datetime
import time
import concurrent.futures
import threading

class BasemappPerformanceTester:
    def __init__(self, base_url="https://chat-sync-1.preview.emergentagent.com"):
        self.base_url = base_url
        self.api_url = f"{base_url}/api"
        self.tests_run = 0
        self.tests_passed = 0

    def run_test(self, name, method, endpoint, expected_status, data=None, token=None, params=None):
        """Run a single API test with timing"""
        url = f"{self.api_url}/{endpoint}"
        headers = {'Content-Type': 'application/json'}
        if token:
            headers['Authorization'] = f'Bearer {token}'

        self.tests_run += 1
        print(f"\nğŸ” Testing {name}...")
        
        start_time = time.time()
        try:
            if method == 'GET':
                response = requests.get(url, headers=headers, params=params, timeout=10)
            elif method == 'POST':
                response = requests.post(url, json=data, headers=headers, timeout=10)
            elif method == 'PUT':
                response = requests.put(url, json=data, headers=headers, timeout=10)

            response_time = time.time() - start_time
            
            success = response.status_code == expected_status
            if success:
                self.tests_passed += 1
                print(f"âœ… Passed - Status: {response.status_code} - Time: {response_time:.3f}s")
                try:
                    return success, response.json(), response_time
                except:
                    return success, {}, response_time
            else:
                print(f"âŒ Failed - Expected {expected_status}, got {response.status_code} - Time: {response_time:.3f}s")
                try:
                    error_detail = response.json()
                    print(f"   Error details: {error_detail}")
                except:
                    print(f"   Response text: {response.text}")
                return False, {}, response_time

        except Exception as e:
            response_time = time.time() - start_time
            print(f"âŒ Failed - Error: {str(e)} - Time: {response_time:.3f}s")
            return False, {}, response_time

    def test_concurrent_registrations(self):
        """Test concurrent user registrations for performance"""
        print("ğŸš€ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ØªØ²Ø§Ù…Ù† Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†")
        print("-" * 50)
        
        def register_user(user_id):
            timestamp = datetime.now().strftime('%H%M%S')
            user_data = {
                "username": f"Ù…Ø³ØªØ®Ø¯Ù…_Ù…ØªØ²Ø§Ù…Ù†_{user_id}_{timestamp}",
                "email": f"concurrent.user.{user_id}.{timestamp}@basemapp.com",
                "password": f"ÙƒÙ„Ù…Ø©_Ù…Ø±ÙˆØ±_Ù‚ÙˆÙŠØ©{user_id}!"
            }
            
            start_time = time.time()
            try:
                response = requests.post(
                    f"{self.api_url}/auth/register",
                    json=user_data,
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
                response_time = time.time() - start_time
                return response.status_code == 200, response_time, user_id
            except Exception as e:
                response_time = time.time() - start_time
                return False, response_time, user_id
        
        # Test with 5 concurrent registrations
        num_concurrent = 5
        start_time = time.time()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_concurrent) as executor:
            futures = [executor.submit(register_user, i) for i in range(num_concurrent)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        total_time = time.time() - start_time
        
        successful = sum(1 for success, _, _ in results if success)
        avg_response_time = sum(time for _, time, _ in results) / len(results)
        
        print(f"   ğŸ“Š Concurrent registrations: {successful}/{num_concurrent}")
        print(f"   â±ï¸ Total time: {total_time:.3f}s")
        print(f"   â±ï¸ Average response time: {avg_response_time:.3f}s")
        print(f"   ğŸš€ Throughput: {num_concurrent/total_time:.2f} requests/second")
        
        self.tests_run += 1
        if successful >= num_concurrent * 0.8:  # 80% success rate
            self.tests_passed += 1
            print("   âœ… Concurrent performance: Good")
            return True
        else:
            print("   âŒ Concurrent performance: Poor")
            return False

    def test_api_response_times(self):
        """Test API response times for different endpoints"""
        print("\nâš¡ Ø§Ø®ØªØ¨Ø§Ø± Ø£ÙˆÙ‚Ø§Øª Ø§Ø³ØªØ¬Ø§Ø¨Ø© API")
        print("-" * 50)
        
        endpoints_to_test = [
            ("POST", "auth/register", "ØªØ³Ø¬ÙŠÙ„ Ù…Ø³ØªØ®Ø¯Ù…", {
                "username": f"speed_test_{datetime.now().strftime('%H%M%S')}",
                "email": f"speed.test.{datetime.now().strftime('%H%M%S')}@basemapp.com",
                "password": "SpeedTest123!"
            }),
            ("POST", "auth/login", "ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ø®Ø§Ø·Ø¦", {
                "email": "invalid@test.com",
                "password": "invalid"
            }),
            ("POST", "auth/verify-email", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯", {
                "email": "test@example.com",
                "code": "123456"
            }),
            ("POST", "auth/resend-verification", "Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªØ­Ù‚Ù‚", {
                "email": "nonexistent@example.com"
            })
        ]
        
        response_times = []
        successful_tests = 0
        
        for method, endpoint, name, data in endpoints_to_test:
            expected_status = 200 if "register" in endpoint else [400, 401, 404]
            
            start_time = time.time()
            try:
                response = requests.post(
                    f"{self.api_url}/{endpoint}",
                    json=data,
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
                response_time = time.time() - start_time
                response_times.append(response_time)
                
                # Check if response is as expected
                if isinstance(expected_status, list):
                    success = response.status_code in expected_status
                else:
                    success = response.status_code == expected_status
                
                if success:
                    successful_tests += 1
                    print(f"   âœ… {name}: {response_time:.3f}s (Status: {response.status_code})")
                else:
                    print(f"   âŒ {name}: {response_time:.3f}s (Status: {response.status_code})")
                    
            except Exception as e:
                response_time = time.time() - start_time
                response_times.append(response_time)
                print(f"   âŒ {name}: {response_time:.3f}s (Error: {str(e)})")
        
        avg_response_time = sum(response_times) / len(response_times)
        max_response_time = max(response_times)
        min_response_time = min(response_times)
        
        print(f"\n   ğŸ“Š Performance Summary:")
        print(f"   â±ï¸ Average response time: {avg_response_time:.3f}s")
        print(f"   â±ï¸ Fastest response: {min_response_time:.3f}s")
        print(f"   â±ï¸ Slowest response: {max_response_time:.3f}s")
        print(f"   âœ… Successful tests: {successful_tests}/{len(endpoints_to_test)}")
        
        self.tests_run += len(endpoints_to_test)
        self.tests_passed += successful_tests
        
        # Performance criteria: average < 2s, max < 5s
        if avg_response_time < 2.0 and max_response_time < 5.0:
            print("   ğŸ‰ Overall performance: Excellent")
            return True
        elif avg_response_time < 3.0 and max_response_time < 8.0:
            print("   âœ… Overall performance: Good")
            return True
        else:
            print("   âš ï¸ Overall performance: Needs improvement")
            return False

    def test_error_handling_performance(self):
        """Test error handling and edge cases"""
        print("\nğŸ›¡ï¸ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø­Ø¯ÙŠØ©")
        print("-" * 50)
        
        error_tests = [
            # Test malformed requests
            ("POST", "auth/register", "Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ù‚ØµØ©", {"username": "test"}),
            ("POST", "auth/login", "Ø¨ÙŠØ§Ù†Ø§Øª ÙØ§Ø±ØºØ©", {}),
            ("POST", "auth/verify-email", "Ø±Ù…Ø² ÙØ§Ø±Øº", {"email": "test@test.com", "code": ""}),
            
            # Test invalid data types
            ("POST", "auth/register", "Ù†ÙˆØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§Ø·Ø¦", {
                "username": 12345,
                "email": "test@test.com",
                "password": "test"
            }),
            
            # Test very long strings
            ("POST", "auth/register", "Ù†Øµ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹", {
                "username": "a" * 1000,
                "email": "test@test.com",
                "password": "test"
            })
        ]
        
        successful_error_handling = 0
        total_error_tests = len(error_tests)
        
        for method, endpoint, name, data in error_tests:
            start_time = time.time()
            try:
                response = requests.post(
                    f"{self.api_url}/{endpoint}",
                    json=data,
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
                response_time = time.time() - start_time
                
                # Error handling is good if it returns 400, 422, or similar client error
                if 400 <= response.status_code < 500:
                    successful_error_handling += 1
                    print(f"   âœ… {name}: {response_time:.3f}s (Status: {response.status_code})")
                else:
                    print(f"   âŒ {name}: {response_time:.3f}s (Status: {response.status_code})")
                    
            except Exception as e:
                response_time = time.time() - start_time
                print(f"   âŒ {name}: {response_time:.3f}s (Error: {str(e)})")
        
        print(f"\n   ğŸ“Š Error Handling Summary:")
        print(f"   âœ… Proper error responses: {successful_error_handling}/{total_error_tests}")
        print(f"   ğŸ“ˆ Error handling rate: {(successful_error_handling/total_error_tests)*100:.1f}%")
        
        self.tests_run += total_error_tests
        self.tests_passed += successful_error_handling
        
        return successful_error_handling >= total_error_tests * 0.8  # 80% success rate

    def run_performance_tests(self):
        """Run comprehensive performance tests"""
        print("ğŸš€ Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª - BasemApp")
        print("=" * 60)
        
        # Test 1: Concurrent Performance
        concurrent_success = self.test_concurrent_registrations()
        
        # Test 2: API Response Times
        response_time_success = self.test_api_response_times()
        
        # Test 3: Error Handling Performance
        error_handling_success = self.test_error_handling_performance()
        
        # Calculate results
        performance_tests = [
            ("Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†", concurrent_success),
            ("Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©", response_time_success),
            ("Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡", error_handling_success)
        ]
        
        passed_performance = sum(1 for _, success in performance_tests if success)
        
        # Print results
        print("\n" + "=" * 60)
        print("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª:")
        print("-" * 40)
        
        for test_name, success in performance_tests:
            status = "âœ… Ù…Ù…ØªØ§Ø²" if success else "âš ï¸ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†"
            print(f"   {test_name}: {status}")
        
        print("-" * 40)
        print(f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {self.tests_run}")
        print(f"ğŸ“ˆ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {self.tests_passed}")
        print(f"ğŸ“ˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ: {(self.tests_passed/self.tests_run)*100:.1f}%")
        print(f"ğŸ“ˆ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {passed_performance}/{len(performance_tests)}")
        
        # Final assessment
        if passed_performance == len(performance_tests):
            print("\nğŸ‰ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡: Ù…Ù…ØªØ§Ø²!")
            print("âœ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªØ²Ø§Ù…Ù† Ù…Ù…ØªØ§Ø²")
            print("âœ… Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø³Ø±ÙŠØ¹Ø©")
            print("âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙØ¹Ù‘Ø§Ù„Ø©")
            print("ğŸš€ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ù†ØªØ§Ø¬ Ø¨Ø£Ø¯Ø§Ø¡ Ø¹Ø§Ù„ÙŠ!")
            return True
        elif passed_performance >= 2:
            print("\nâœ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡: Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹!")
            print("âœ… Ù…Ø¹Ø¸Ù… Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø²Ø©")
            print("âš ï¸ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø·ÙÙŠÙØ© Ù…Ø·Ù„ÙˆØ¨Ø©")
            return True
        else:
            print("\nâš ï¸ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡: ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†")
            print("ğŸ”§ Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡")
            return False

def main():
    tester = BasemappPerformanceTester()
    success = tester.run_performance_tests()
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())